{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from math import exp, log\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text2sentences(path):\n",
    "    # feel free to make a better tokenization/pre-processing\n",
    "    sentences = []\n",
    "    reg = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    with open(path) as f:\n",
    "        for l in f:\n",
    "            l_wo_punct = reg.sub('', l)\n",
    "            sentences.append( l_wo_punct.lower().split() )\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = text2sentences(\"data/odyssey.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'prophesyings', 'with', 'which', 'phoebus', 'apollo', 'had', 'inspired', 'him', 'with']\n"
     ]
    }
   ],
   "source": [
    "sent = sentences[80]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_voc(voc_dict, word, index):\n",
    "    # (word: index)\n",
    "    if word not in voc_dict:\n",
    "        voc_dict[word] = index\n",
    "        index += 1\n",
    "    return voc_dict, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPairsAndVocs(sentences, winSize):\n",
    "    wc_pairs = []\n",
    "    word_voc = {}\n",
    "    word_index = 0\n",
    "    context_voc = {}\n",
    "    context_index = 0\n",
    "    \n",
    "    for sent in sentences:\n",
    "        for i in range(len(sent)):\n",
    "            word = sent[i]\n",
    "            # Update word_voc dict\n",
    "            word_voc, word_index = update_voc(word_voc, word, word_index)\n",
    "            for j in range(max(0,i-winSize), min(i+winSize+1, len(sent))):\n",
    "                if i != j:\n",
    "                    context = sent[j]\n",
    "                    context_voc, context_index = update_voc(context_voc, context, context_index)\n",
    "                    wc_pairs.append((word_voc[word], context_voc[context]))\n",
    "                    \n",
    "    return wc_pairs, word_voc, context_voc\n",
    "\n",
    "def getNegPairs(wc_pairs, word_voc, context_voc):\n",
    "    word_voc_list = list(word_voc.keys())\n",
    "    context_voc_list = list(context_voc.keys())\n",
    "    \n",
    "    nb_words = len(word_voc_list)\n",
    "    nb_contexts = len(context_voc_list)\n",
    "    \n",
    "    nb_pairs = len(wc_pairs)\n",
    "    neg_wc_pairs = []\n",
    "\n",
    "    for _ in range(nb_pairs):\n",
    "        ind1 = np.random.randint(0,nb_words)\n",
    "        ind2 = np.random.randint(0,nb_contexts)\n",
    "        neg_wc_pairs.append((ind1, ind2))\n",
    "    return neg_wc_pairs\n",
    "    \n",
    "def costFunction(theta, nEmbed, wc_pairs, neg_wc_pairs, nb_words, nb_contexts):\n",
    "    print(\"Appel cost function\")\n",
    "    W = theta[:nEmbed*nb_words].reshape(nEmbed, nb_words)\n",
    "    C = theta[nEmbed*nb_words:].reshape(nEmbed, nb_contexts)\n",
    "    \n",
    "    S = W.transpose().dot(C)\n",
    "    \n",
    "    wc_cost = sum([-log(1+exp(-S[wc_pair])) for wc_pair in wc_pairs])\n",
    "    \n",
    "    neg_wc_cost = 0\n",
    "    for neg_wc_pair in neg_wc_pairs:\n",
    "        #print(1+exp(S[neg_wc_pair]))\n",
    "        neg_wc_cost += -log(1+exp(S[neg_wc_pair]))\n",
    "    \n",
    "    #neg_wc_cost = sum([log(exp(-S[neg_wc_pair])/(1+exp(-S[neg_wc_pair]))) for neg_wc_pair in neg_wc_pairs])\n",
    "    \n",
    "    return - wc_cost - neg_wc_cost\n",
    "\n",
    "def gradCost(theta, nEmbed, wc_pairs, neg_wc_pairs, nb_words, nb_contexts):\n",
    "    print(\"Appel gradient\")\n",
    "    grad = np.zeros(theta.shape[0])\n",
    "    W = theta[:nEmbed*nb_words].reshape(nEmbed, nb_words)\n",
    "    C = theta[nEmbed*nb_words:].reshape(nEmbed, nb_contexts)\n",
    "    \n",
    "    S = W.transpose().dot(C)\n",
    "    \n",
    "    print(\"Début wc pairs\")\n",
    "    c = 0\n",
    "    for wc_pair in wc_pairs:\n",
    "        c+=1\n",
    "        word_idx = wc_pair[0]\n",
    "        context_idx = wc_pair[1]\n",
    "        \n",
    "        exp_mwdotc = exp(-S[wc_pair])\n",
    "        \n",
    "        # Update the derivative for word and context\n",
    "        df_dw = C[:,context_idx]*exp_mwdotc/(1+exp_mwdotc)\n",
    "        grad[word_idx*nEmbed:(word_idx+1)*nEmbed] += df_dw\n",
    "        df_dc = W[:,word_idx]*exp_mwdotc/(1+exp_mwdotc)\n",
    "        grad[context_idx*nEmbed:(context_idx+1)*nEmbed] += df_dc\n",
    "    \n",
    "    print(\"Début neg wc pairs\")\n",
    "    for neg_wc_pair in neg_wc_pairs:\n",
    "        word_idx = neg_wc_pair[0]\n",
    "        context_idx = neg_wc_pair[1]\n",
    "        \n",
    "        exp_wdotc = exp(S[neg_wc_pair])\n",
    "        \n",
    "        # Update the derivative for word and context\n",
    "        df_dw = -C[:,context_idx]*exp_wdotc/(1+exp_wdotc)\n",
    "        grad[word_idx*nEmbed:(word_idx+1)*nEmbed] += df_dw\n",
    "        \n",
    "        df_dc = -W[:,word_idx]*exp_wdotc/(1+exp_wdotc)\n",
    "        grad[context_idx*nEmbed:(context_idx+1)*nEmbed] += df_dc\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mSkipGram:\n",
    "    \n",
    "    def __init__(self,sentences, nEmbed=50, negativeRate=5, winSize=1, minCount=5):\n",
    "        self.nEmbed = nEmbed\n",
    "        self.wc_pairs, self.word_voc, self.context_voc = getPairsAndVocs(sentences, winSize)\n",
    "        self.neg_wc_pairs = getNegPairs(self.wc_pairs, self.word_voc, self.context_voc)\n",
    "    \n",
    "    def train(self):\n",
    "        nb_words = len(list(self.word_voc.keys()))\n",
    "        nb_context = len(list(self.context_voc.keys()))\n",
    "        \n",
    "        theta0 = np.ones((nb_words+nb_context)*self.nEmbed)*0.01\n",
    "        cost_to_optimize = lambda theta: costFunction(theta, self.nEmbed, self.wc_pairs, self.neg_wc_pairs, nb_words, nb_context)\n",
    "        grad = lambda theta: gradCost(theta, self.nEmbed, self.wc_pairs, self.neg_wc_pairs, nb_words, nb_context)\n",
    "        \n",
    "        ####### GRADIENT DESCENT #######\n",
    "        converged = False\n",
    "        itermax = 1000\n",
    "        tol = 1e-6\n",
    "        thetan = theta0\n",
    "        fn = cost_to_optimize(thetan)\n",
    "        print(fn)\n",
    "        rho = 0.01\n",
    "        it = 0\n",
    "        \n",
    "        while not converged and it < itermax:\n",
    "            it+=1\n",
    "            gradn = grad(thetan)\n",
    "            thetanp1 = thetan + rho*gradn\n",
    "            fnp1 = cost_to_optimize(thetanp1)\n",
    "            print(fnp1)\n",
    "            thetan = thetanp1\n",
    "            fn = fnp1\n",
    "        ####### GRADIENT DESCENT #######   \n",
    "        \n",
    "        return (fn, thetan, converged)\n",
    "\n",
    "my_sg = mSkipGram(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel cost function\n",
      "389117.945933477\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388928.0479586347\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388735.33474611817\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388551.63089107396\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388408.2740327246\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388341.97652589553\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388364.4820358639\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388467.03936034505\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388643.9981963306\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "388897.22698573937\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "389232.1432096518\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "389654.91685382306\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "390171.20230965194\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n",
      "Appel cost function\n",
      "390785.57362524344\n",
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a88c5fc5772f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_sg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-e997f53faafc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconverged\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mitermax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mit\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mgradn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mthetanp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetan\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mfnp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_to_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetanp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-e997f53faafc>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtheta0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_words\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnb_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEmbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcost_to_optimize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEmbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwc_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_wc_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgradCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEmbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwc_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_wc_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m####### GRADIENT DESCENT #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-4beeadcf78f3>\u001b[0m in \u001b[0;36mgradCost\u001b[0;34m(theta, nEmbed, wc_pairs, neg_wc_pairs, nb_words, nb_contexts)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mcontext_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_wc_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mexp_wdotc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_wc_pair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Update the derivative for word and context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = my_sg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280688"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_sg.wc_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_words = len(list(my_sg.word_voc.keys()))\n",
    "nb_context = len(list(my_sg.context_voc.keys()))\n",
    "theta0 = np.ones((nb_words+nb_context)*my_sg.nEmbed)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel cost function\n"
     ]
    }
   ],
   "source": [
    "%lprun -f costFunction costFunction(theta0, my_sg.nEmbed, my_sg.wc_pairs, my_sg.neg_wc_pairs, nb_words, nb_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appel gradient\n",
      "Début wc pairs\n",
      "Début neg wc pairs\n"
     ]
    }
   ],
   "source": [
    "%lprun -f gradCost gradCost(theta0, my_sg.nEmbed, my_sg.wc_pairs, my_sg.neg_wc_pairs, nb_words, nb_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
